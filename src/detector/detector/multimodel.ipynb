{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7eHgv8OUuaI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import re \n",
        "import datetime\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers, optimizers\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense, Dropout, LSTM, Softmax, Bidirectional, Conv1D, Conv2D, MaxPooling2D, Flatten, Reshape, LayerNormalization, BatchNormalization\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M13ahgc_xB8Y",
        "outputId": "123c374e-c0b5-472b-9680-93efa627c650"
      },
      "outputs": [],
      "source": [
        "print(f\"{tf.__version__=}\")\n",
        "print(f\"{np.__version__=}\")\n",
        "print(\"nvidia-smi\")\n",
        "!nvidia-smi\n",
        "print(\"nvcc version\")\n",
        "!nvcc --version\n",
        "print(\"nvinfer version\")\n",
        "!dpkg -l | grep nvinfer\n",
        "print(\"TensorRT version\")\n",
        "!dpkg -l | grep TensorRT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxgFSsAOLniB"
      },
      "source": [
        "# Load & Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YTvq7NLucIq"
      },
      "outputs": [],
      "source": [
        "GESTRUES = [\"STATIC\", \"SLIDE_UP\", \"SLIDE_DOWN\", \"SLIDE_LEFT\", \"SLIDE_RIGHT\", \"RELEASE\", \"GRASP\", \"HIGHLIGHT\", \"ON_YES\", \"OFF_NO\", \"NONE\",]\n",
        "NUM_CLASSES = len(GESTRUES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yh72CyqaF9US",
        "outputId": "03f64ef7-5f92-4a56-ae80-203b7548cf89"
      },
      "outputs": [],
      "source": [
        "def load_data(filepath='/home/ubuntu/FYP-ROS/rosbag/bag/info.txt'):\n",
        "    global GESTRUES\n",
        "    dataset = {}\n",
        "    with open(filepath, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            for gesture in GESTRUES:\n",
        "                if line.startswith(f'{gesture}:'):\n",
        "                    key = gesture\n",
        "                    dataset[key] = []\n",
        "                    break\n",
        "            else:\n",
        "                if line != '':\n",
        "                    dataset[key].append(line.split()[-1])\n",
        "    return dataset\n",
        "\n",
        "DATA_BUF_LEN = 100\n",
        "def get_data_by_id(data_id, augment):\n",
        "    data_root = \"/home/ubuntu/FYP-ROS/rosbag/data\"\n",
        "\n",
        "    x_raw = pd.read_csv(f\"{data_root}/data_clean_augment/{data_id}_data{augment}.csv\")\n",
        "    x_raw = x_raw.drop([\n",
        "        \"timestamp\", \n",
        "        \"imu0_to_imu1_rotation_x\", \"imu0_to_imu1_rotation_y\", \"imu0_to_imu1_rotation_z\", \"imu0_to_imu1_rotation_w\",\n",
        "        \"imu0_to_imu2_rotation_x\", \"imu0_to_imu2_rotation_y\", \"imu0_to_imu2_rotation_z\", \"imu0_to_imu2_rotation_w\"], axis=1)\n",
        "\n",
        "    x_raw = x_raw.to_numpy()\n",
        "    if x_raw.shape[0] < DATA_BUF_LEN:\n",
        "        last_row = np.repeat([x_raw[-1]], repeats=DATA_BUF_LEN-x_raw.shape[0], axis=0)\n",
        "        x_raw = np.vstack([x_raw, last_row])\n",
        "    else:\n",
        "        x_raw = x_raw[:DATA_BUF_LEN]\n",
        "\n",
        "    y_label = pd.read_csv(f\"{data_root}/label_clean_augment/{data_id}_label{augment}.csv\")['label']\n",
        "    return x_raw, y_label\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "metadata = load_data()\n",
        "for gesture in GESTRUES[:7]:\n",
        "    print(f\"{gesture}: {len(metadata[gesture])}\")\n",
        "    for data_id in metadata[gesture]:\n",
        "        x_raw, y_label = get_data_by_id(data_id, augment=\"\")\n",
        "        X.append(x_raw)\n",
        "        y.append(y_label)\n",
        "\n",
        "        x_jitter, y_label = get_data_by_id(data_id, augment=\"_jitter\")\n",
        "        X.append(x_jitter)\n",
        "        y.append(y_label)\n",
        "        \n",
        "        x_time_warp, y_label = get_data_by_id(data_id, augment=\"_time_warp\")\n",
        "        X.append(x_time_warp)\n",
        "        y.append(y_label)\n",
        "\n",
        "        x_time_warp2, y_label = get_data_by_id(data_id, augment=\"_time_warp2\")\n",
        "        X.append(x_time_warp2)\n",
        "        y.append(y_label)\n",
        "\n",
        "X = np.array(X)\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=NUM_CLASSES)\n",
        "FEATURES_DIM = X.shape[2]\n",
        "\n",
        "# print dimension\n",
        "print(f\"{X.shape=}\")\n",
        "print(f\"{y.shape=}\")\n",
        "\n",
        "print(f\"{X[1]=}\")\n",
        "print(f\"{y[100]=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5Uyo2-Sg6dY"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot\n",
        "y_sum = np.sum(y, axis=0)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(GESTRUES, y_sum)\n",
        "plt.title(\"Number of samples per gesture\")\n",
        "plt.xlabel(\"Gesture\")\n",
        "plt.xticks(fontsize=7)\n",
        "plt.ylabel(\"Number of samples\")\n",
        "for i, v in enumerate(y_sum):\n",
        "    plt.text(i, v+1, str(v), ha='center', fontsize=10)\n",
        "\n",
        "y_test_sum = np.sum(y_test, axis=0)\n",
        "plt.bar(GESTRUES, y_test_sum)\n",
        "for i, v in enumerate(y_test_sum):\n",
        "    plt.text(i, v+1, str(v), ha='center', fontsize=10)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcsjnPznl4uw"
      },
      "source": [
        "# Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ-alFKYzmsw",
        "outputId": "17a0a44a-bcb7-45c9-ca06-a8d248ef8b88"
      },
      "outputs": [],
      "source": [
        "kernal_reg = 5e-3\n",
        "bias_reg = 1e-4\n",
        "\n",
        "inputs = keras.Input((DATA_BUF_LEN, FEATURES_DIM))\n",
        "x1 = Reshape(target_shape=(DATA_BUF_LEN, FEATURES_DIM ,1))(inputs)\n",
        "x1 = Conv2D(32, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(kernal_reg), bias_regularizer=regularizers.l2(bias_reg), name='Conv2DL1')(x1)\n",
        "x1 = MaxPooling2D(pool_size=(2, 2), name='MaxPoolL1')(x1)\n",
        "x1 = LayerNormalization(name='LayerNormL1')(x1)\n",
        "x1 = Flatten(name='FlattenL1')(x1)\n",
        "\n",
        "x2 = Bidirectional(LSTM(units=64, kernel_regularizer=regularizers.L2(kernal_reg), bias_regularizer=regularizers.L2(bias_reg), return_sequences=True), name='BiLSTM1')(inputs)\n",
        "x2 = LayerNormalization(name='LayerNormR1')(x2)\n",
        "x2 = Bidirectional(LSTM(units=64, kernel_regularizer=regularizers.L2(kernal_reg), bias_regularizer=regularizers.L2(bias_reg), return_sequences=True), name='BiLSTM2')(x2)\n",
        "x2 = LayerNormalization(name='LayerNormR2')(x2)\n",
        "x2 = Flatten(name='FlattenR1')(x2)\n",
        "\n",
        "x = keras.layers.concatenate([x1, x2], axis=-1)\n",
        "x = LayerNormalization(name='LayerNormC1')(x)\n",
        "output = Dense(NUM_CLASSES,activation='softmax', kernel_regularizer=regularizers.L2(kernal_reg), bias_regularizer=regularizers.L2(bias_reg), name='Dense3')(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=output, name=\"mnist_model\")\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy'])\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aq8Yr_zojE8d"
      },
      "outputs": [],
      "source": [
        "# model.load_weights(\"/home/ubuntu/FYP-ROS/weights/model_lstm_weights-2023_2_24-14_51-acc0.96.h5\")\n",
        "# model = keras.models.load_model(\"/home/ubuntu/FYP-ROS/weights/model_lstm-2023_2_25-14_38-acc0.94\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14cv8JmKl6Pk"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n39iA43NF62t",
        "outputId": "5ae05e20-108a-4f58-c5af-b3061017a402"
      },
      "outputs": [],
      "source": [
        "ACCURACY_THRESHOLD = 0.99\n",
        "class accuryThreasholdCallback(tf.keras.callbacks.Callback): \n",
        "    def on_epoch_end(self, epoch, logs={}): \n",
        "        if(logs.get('accuracy') > ACCURACY_THRESHOLD and logs.get('val_accuracy') > ACCURACY_THRESHOLD):   \n",
        "            print(\"\\nReached %2.2f%% accuracy, so stopping training!!\" %(ACCURACY_THRESHOLD*100))   \n",
        "            self.model.stop_training = True\n",
        "\n",
        "accuracy_threashold_monitor = accuryThreasholdCallback()\n",
        "early_stopping_monitor = EarlyStopping(patience=3)\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32, callbacks=[accuracy_threashold_monitor])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "v5rhMIU3_p7w",
        "outputId": "d9bf9d8d-3e23-4f10-cab5-7438822559de"
      },
      "outputs": [],
      "source": [
        "print(history.history.keys())\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
        "ax[0].plot(history.history['accuracy'])\n",
        "ax[0].plot(history.history['val_accuracy'])\n",
        "ax[0].set_ylabel('accuracy')\n",
        "ax[0].set_xlabel('epoch')\n",
        "ax[0].legend(['train', 'val'], loc='upper right')\n",
        "\n",
        "ax[1].plot(history.history['loss'])\n",
        "ax[1].plot(history.history['val_loss'])\n",
        "ax[1].set_ylabel('loss')\n",
        "ax[1].set_xlabel('epoch')\n",
        "ax[1].legend(['train', 'val'], loc='upper right')\n",
        "fig.suptitle('Model training history')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv3I2Xr3jqts"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_25YJpdPPwK5",
        "outputId": "7608f1b3-7ddc-4d8b-c1e9-6ecc60ae29fa"
      },
      "outputs": [],
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"{scores=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Med8GgsumOZX",
        "outputId": "a99bb866-0de3-462f-c0ae-1525ae0f9e15"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# print(f\"{np.argmax(y_pred, axis=1)=}\")\n",
        "# print(f\"{np.argmax(y_test, axis=1)=}\")\n",
        "\n",
        "error_data_index = []\n",
        "for i, (yp, yt) in enumerate(zip(np.argmax(y_pred, axis=1), np.argmax(y_test, axis=1))):\n",
        "    if yp != yt:\n",
        "        print(f\"index: {i}, truth: {GESTRUES[yt]}, predicted: {GESTRUES[yp]}\")\n",
        "        error_data_index.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "dYxrNLa_tbEI",
        "outputId": "157bff66-e04d-4fc6-8505-e0d3b550a627"
      },
      "outputs": [],
      "source": [
        "y_test_not_onehot = np.argmax(y_test, axis=1)\n",
        "y_pred_not_onehot = np.argmax(y_pred, axis=1)\n",
        "plt.figure(figsize=(10, 10))\n",
        "matrix_confusion = confusion_matrix(y_pred_not_onehot, y_test_not_onehot)\n",
        "sns.heatmap(matrix_confusion, square=True, annot=False, cmap='Blues', fmt='d')\n",
        "\n",
        "for i in range(matrix_confusion.shape[0]):\n",
        "    for j in range(matrix_confusion.shape[1]):\n",
        "        plt.text(j+0.5, i+0.5, f'{matrix_confusion[i, j]}/{np.sum(matrix_confusion[i, :])}', \n",
        "                 horizontalalignment='center', verticalalignment='center', fontsize=7)\n",
        "\n",
        "plt.xlabel('ground truth')\n",
        "plt.ylabel('predictions')\n",
        "plt.xticks(np.arange(0.5, matrix_confusion.shape[0]+0.5), GESTRUES, rotation=45, fontsize=7)\n",
        "plt.yticks(np.arange(0.5, matrix_confusion.shape[0]+0.5), GESTRUES, rotation=45, fontsize=7)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "id": "HJrkHzcfDxRN",
        "outputId": "e4edfe68-cdc5-497f-fc94-788f60c797a0"
      },
      "outputs": [],
      "source": [
        "print(f\"total error data size: {len(error_data_index)}\")\n",
        "index = error_data_index[1]\n",
        "\n",
        "true_label = np.argmax(y_test[index])\n",
        "predicted_class = np.argmax(y_pred[index])\n",
        "\n",
        "print(f\"{GESTRUES[true_label]=}\")\n",
        "print(f\"{GESTRUES[predicted_class]=}\")\n",
        "\n",
        "fig, axs = plt.subplots(3, 6, figsize=(20, 10))\n",
        "\n",
        "raw_data = X_test[index]\n",
        "acc_axes = axs[:, :3].ravel()\n",
        "vel_axes = axs[:, 3:].ravel()\n",
        "acc_data = np.concatenate([raw_data[:,1:4], raw_data[:,11:14], raw_data[:,21:24]], axis=1)\n",
        "vel_data = np.concatenate([raw_data[:,4:7], raw_data[:,14:17], raw_data[:,24:27]], axis=1)\n",
        "acc_titles = [f'Imu{i}_acc_{xyz}' for i in range(3) for xyz in ['x', 'y', 'z']]\n",
        "vel_titles = [f'Imu{i}_vel_{xyz}' for i in range(3) for xyz in ['x', 'y', 'z']]\n",
        "\n",
        "for ax, data, title in zip(acc_axes, acc_data.T, acc_titles):\n",
        "    ax.plot(data)\n",
        "    ax.set_title(title)\n",
        "    ax.set_ylim([-1.5 * 9.8, 1.5 * 9.8])\n",
        "    \n",
        "for ax, data, title in zip(vel_axes, vel_data.T, vel_titles):\n",
        "    ax.plot(data)\n",
        "    ax.set_title(title)\n",
        "    ax.set_ylim([-5, 5])\n",
        "\n",
        "fig.suptitle(f'labeled: {GESTRUES[true_label]}, predicted: {GESTRUES[predicted_class]}')\n",
        "plt.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExqD0F92bGNb"
      },
      "source": [
        "# Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9kw6VNFbF_m"
      },
      "outputs": [],
      "source": [
        "t = datetime.datetime.now()\n",
        "t_str = f\"{t.year}_{t.month}_{t.day}-{t.hour}_{t.minute}\"\n",
        "acc_str = f\"{scores[1]:.2f}\" \n",
        "# model.save_weights(f'/home/ubuntu/FYP-ROS/weights/model_cnn_weights-{t_str}-acc{acc_str}.h5')\n",
        "# model.save(f'/home/ubuntu/FYP-ROS/weights/model_cnn-{t_str}-acc{acc_str}.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cf_SnLotUIXu"
      },
      "source": [
        "# Explaination "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_4S-pRiULfn"
      },
      "outputs": [],
      "source": [
        "# !pip install shap\n",
        "# import shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jM_HRRVCUHVB"
      },
      "outputs": [],
      "source": [
        "# explainer = shap.Explainer(model)\n",
        "# shap_values = explainer(X_train.transpose(0, 2, 1))\n",
        "# shap.summary_plot(shap_values, X_train.transpose(0, 2, 1))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
