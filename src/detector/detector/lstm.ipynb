{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7eHgv8OUuaI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import datetime\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers, optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense, Flatten, Dropout, LSTM, Softmax, Bidirectional, LayerNormalization, BatchNormalization, Conv1D, MaxPooling1D, Input\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tqdm\n",
        "\n",
        "os.sys.path.append('/home/ubuntu/FYP-ROS/src/utils/utils')\n",
        "from data_loading import load_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M13ahgc_xB8Y",
        "outputId": "123c374e-c0b5-472b-9680-93efa627c650"
      },
      "outputs": [],
      "source": [
        "print(f\"{tf.__version__=}\")\n",
        "print(f\"{np.__version__=}\")\n",
        "print(\"nvidia-smi\")\n",
        "!nvidia-smi\n",
        "print(\"nvcc version\")\n",
        "!nvcc --version\n",
        "print(\"nvinfer version\")\n",
        "!dpkg -l | grep nvinfer\n",
        "print(\"TensorRT version\")\n",
        "!dpkg -l | grep TensorRT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxgFSsAOLniB"
      },
      "source": [
        "# Load & Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YTvq7NLucIq"
      },
      "outputs": [],
      "source": [
        "GESTURES = [\"STATIC\", \"SLIDE_UP\", \"SLIDE_DOWN\", \"SLIDE_LEFT\", \"SLIDE_RIGHT\", \"RELEASE\", \"GRASP\", \"HIGHLIGHT\", \"ON_YES\", \"OFF_NO\", \"NONE\", \"POINTING\"]\n",
        "GESTURES_KEPT = [\"STATIC\", \"SLIDE_UP\", \"SLIDE_DOWN\", \"RELEASE\", \"GRASP\", \"POINTING\"]\n",
        "GESTURES_DISCARDED = [g for g in GESTURES if g not in GESTURES_KEPT]\n",
        "NUM_CLASSES = len(GESTURES)\n",
        "\n",
        "FEATURES = [\"timestamp\", \n",
        "        \"Imu0_linear_acceleration_x\", \"Imu0_linear_acceleration_y\", \"Imu0_linear_acceleration_z\",\n",
        "        \"Imu0_angular_velocity_x\", \"Imu0_angular_velocity_y\", \"Imu0_angular_velocity_z\",\n",
        "        \"Imu0_orientation_x\", \"Imu0_orientation_y\", \"Imu0_orientation_z\", \"Imu0_orientation_w\",\n",
        "        \"Imu1_linear_acceleration_x\", \"Imu1_linear_acceleration_y\", \"Imu1_linear_acceleration_z\",\n",
        "        \"Imu1_angular_velocity_x\", \"Imu1_angular_velocity_y\", \"Imu1_angular_velocity_z\",\n",
        "        \"Imu1_orientation_x\", \"Imu1_orientation_y\", \"Imu1_orientation_z\", \"Imu1_orientation_w\",\n",
        "        \"Imu2_linear_acceleration_x\", \"Imu2_linear_acceleration_y\", \"Imu2_linear_acceleration_z\",\n",
        "        \"Imu2_angular_velocity_x\", \"Imu2_angular_velocity_y\", \"Imu2_angular_velocity_z\",\n",
        "        \"Imu2_orientation_x\", \"Imu2_orientation_y\", \"Imu2_orientation_z\", \"Imu2_orientation_w\",\n",
        "        \"imu0_to_imu1_rotation_x\", \"imu0_to_imu1_rotation_y\", \"imu0_to_imu1_rotation_z\", \"imu0_to_imu1_rotation_w\",\n",
        "        \"imu0_to_imu2_rotation_x\", \"imu0_to_imu2_rotation_y\", \"imu0_to_imu2_rotation_z\", \"imu0_to_imu2_rotation_w\",\n",
        "        \"imu0_to_imu1_translation_x\", \"imu0_to_imu1_translation_y\", \"imu0_to_imu1_translation_z\",\n",
        "        \"imu0_to_imu2_translation_x\", \"imu0_to_imu2_translation_y\", \"imu0_to_imu2_translation_z\",]\n",
        "FEATURES_KEPT = [\"Imu0_linear_acceleration_x\", \"Imu0_linear_acceleration_y\", \"Imu0_linear_acceleration_z\",\n",
        "                 \"Imu1_linear_acceleration_x\", \"Imu1_linear_acceleration_y\", \"Imu1_linear_acceleration_z\",\n",
        "                 \"Imu2_linear_acceleration_x\", \"Imu2_linear_acceleration_y\", \"Imu2_linear_acceleration_z\"]\n",
        "FEATURES_DROPPED = [f for f in FEATURES if f not in FEATURES_KEPT]\n",
        "FEATURES_DIM = len(FEATURES_KEPT)\n",
        "\n",
        "print(f\"{NUM_CLASSES=}\")\n",
        "print(f\"{FEATURES_DIM=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yh72CyqaF9US",
        "outputId": "03f64ef7-5f92-4a56-ae80-203b7548cf89"
      },
      "outputs": [],
      "source": [
        "DATA_BUF_LEN = 50\n",
        "def get_data_by_id(data_id, augment):\n",
        "    data_root = \"/home/ubuntu/FYP-ROS/rosbag/data\"\n",
        "\n",
        "    x_raw = pd.read_csv(f\"{data_root}/data_clean_augment/{data_id}_data{augment}.csv\")\n",
        "    x_raw = x_raw.drop(FEATURES_DROPPED, axis=1)\n",
        "    if 'timestamp' in x_raw.columns:\n",
        "        x_raw['timestamp'] = x_raw['timestamp'] - x_raw['timestamp'].iloc[0]\n",
        "    \n",
        "    x_raw = x_raw.to_numpy()\n",
        "    \n",
        "    if x_raw.shape[0] < DATA_BUF_LEN:\n",
        "        last_row = np.repeat([x_raw[-1]], repeats=DATA_BUF_LEN-x_raw.shape[0], axis=0)\n",
        "        x_raw = np.vstack([x_raw, last_row])\n",
        "    else:\n",
        "        x_raw = x_raw[:DATA_BUF_LEN]\n",
        "\n",
        "    y_label = pd.read_csv(f\"{data_root}/label_clean_augment/{data_id}_label{augment}.csv\")['label']\n",
        "    y_label = tf.keras.utils.to_categorical(y_label, num_classes=NUM_CLASSES)[0]\n",
        "    return x_raw, y_label\n",
        "\n",
        "df = pd.DataFrame()\n",
        "metadata, cnt = load_data(ignore_classes=GESTURES_DISCARDED, ignore_dates=[\"Mar 23\"])\n",
        "\n",
        "for gesture_type in tqdm.tqdm(metadata):\n",
        "    for data_id in metadata[gesture_type]:\n",
        "        x_raw, y_label = get_data_by_id(data_id, augment=\"\")\n",
        "        df = pd.concat([df, pd.DataFrame({\"data_id\": data_id, \"data\": [x_raw], \"label\": [y_label]})], ignore_index=False)\n",
        "        \n",
        "        x_jitter, y_label = get_data_by_id(data_id, augment=\"_jitter\")\n",
        "        df = pd.concat([df, pd.DataFrame({\"data_id\": data_id, \"data\": [x_jitter], \"label\": [y_label]})], ignore_index=False)\n",
        "\n",
        "        x_time_warp, y_label = get_data_by_id(data_id, augment=\"_time_warp\")\n",
        "        df = pd.concat([df, pd.DataFrame({\"data_id\": data_id, \"data\": [x_time_warp], \"label\": [y_label]})], ignore_index=False)\n",
        "\n",
        "        x_time_warp2, y_label = get_data_by_id(data_id, augment=\"_time_warp2\")\n",
        "        df = pd.concat([df, pd.DataFrame({\"data_id\": data_id, \"data\": [x_time_warp2], \"label\": [y_label]})], ignore_index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5Uyo2-Sg6dY"
      },
      "outputs": [],
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(np.array(df[\"data\"].to_list()), np.array(df[\"label\"].to_list()), test_size=0.1)\n",
        "\n",
        "print(f\"{X_train.shape=}\")\n",
        "print(f\"{X_valid.shape=}\")\n",
        "print(f\"{y_train.shape=}\")\n",
        "print(f\"{y_valid.shape=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot\n",
        "y_train_sum = np.sum(y_train, axis=0)\n",
        "y_train_sum = y_train_sum[y_train_sum != 0]\n",
        "plt.figure(figsize=(13, 5))\n",
        "plt.bar(GESTURES_KEPT, y_train_sum)\n",
        "plt.title(\"Number of samples per gesture\", fontdict={'fontsize': 14})\n",
        "plt.xlabel(\"Gesture\", fontdict={'fontsize': 12})\n",
        "plt.xticks(fontsize=12)\n",
        "plt.ylabel(\"Number of samples\", fontdict={'fontsize': 12})\n",
        "for i, v in enumerate(y_train_sum):\n",
        "    plt.text(i, v+1, str(v), ha='center', fontsize=12)\n",
        "\n",
        "y_valid_sum = np.sum(y_valid, axis=0)\n",
        "y_valid_sum = y_valid_sum[y_valid_sum != 0]\n",
        "plt.bar(GESTURES_KEPT, y_valid_sum)\n",
        "for i, v in enumerate(y_valid_sum):\n",
        "    plt.text(i, v+1, str(v), ha='center', fontsize=12)\n",
        "\n",
        "plt.legend([\"train\", \"valid\"],prop={'size': 12})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcsjnPznl4uw"
      },
      "source": [
        "# Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ-alFKYzmsw",
        "outputId": "17a0a44a-bcb7-45c9-ca06-a8d248ef8b88"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "kernal_reg = 1e-2\n",
        "bias_reg = 1e-2\n",
        "\n",
        "model.add(Input(shape=(DATA_BUF_LEN, FEATURES_DIM)))\n",
        "model.add(LSTM(units=64, kernel_regularizer=regularizers.L2(kernal_reg), bias_regularizer=regularizers.L2(bias_reg), return_sequences=True, name='LSTM1'))\n",
        "model.add(Dropout(0.5, name='Dropout1'))\n",
        "model.add(LayerNormalization())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, kernel_regularizer=regularizers.L2(kernal_reg), bias_regularizer=regularizers.L2(bias_reg), activation='relu', name='Dense1'))\n",
        "model.add(Dropout(0.5, name='Dropout2'))\n",
        "model.add(LayerNormalization())\n",
        "model.add(Dense(NUM_CLASSES, activation='softmax', kernel_regularizer=regularizers.L2(kernal_reg), bias_regularizer=regularizers.L2(bias_reg), name='Dense2'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.Adam(learning_rate=0.0005),\n",
        "              metrics=['accuracy'])\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aq8Yr_zojE8d"
      },
      "outputs": [],
      "source": [
        "# model.load_weights(\"/home/ubuntu/FYP-ROS/weights/model_lstm_weights-2023_2_24-14_51-acc0.96.h5\")\n",
        "# model = keras.models.load_model(\"/home/ubuntu/FYP-ROS/weights/model_lstm-2023_3_31-15_34-acc0.99.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14cv8JmKl6Pk"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n39iA43NF62t",
        "outputId": "5ae05e20-108a-4f58-c5af-b3061017a402"
      },
      "outputs": [],
      "source": [
        "ACCURACY_THRESHOLD = 0.99\n",
        "class accuryThreasholdCallback(tf.keras.callbacks.Callback): \n",
        "    def on_epoch_end(self, epoch, logs={}): \n",
        "        if(logs.get('accuracy') > ACCURACY_THRESHOLD and logs.get('val_accuracy') > ACCURACY_THRESHOLD):   \n",
        "            print(\"\\nReached %2.2f%% accuracy, so stopping training!!\" %(ACCURACY_THRESHOLD*100))   \n",
        "            self.model.stop_training = True\n",
        "\n",
        "accuracy_threashold_monitor = accuryThreasholdCallback()\n",
        "early_stopping_monitor = EarlyStopping(patience=3)\n",
        "\n",
        "history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=30, batch_size=32, callbacks=[accuracy_threashold_monitor])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "v5rhMIU3_p7w",
        "outputId": "d9bf9d8d-3e23-4f10-cab5-7438822559de"
      },
      "outputs": [],
      "source": [
        "print(history.history.keys())\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
        "ax[0].plot(history.history['accuracy'])\n",
        "ax[0].plot(history.history['val_accuracy'])\n",
        "ax[0].set_ylabel('accuracy')\n",
        "ax[0].set_xlabel('epoch')\n",
        "\n",
        "ax[1].plot(history.history['loss'])\n",
        "ax[1].plot(history.history['val_loss'])\n",
        "ax[1].set_ylabel('loss')\n",
        "ax[1].set_xlabel('epoch')\n",
        "fig.legend(['train', 'val'], loc='upper right')\n",
        "fig.suptitle('Model training history')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv3I2Xr3jqts"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_25YJpdPPwK5",
        "outputId": "7608f1b3-7ddc-4d8b-c1e9-6ecc60ae29fa"
      },
      "outputs": [],
      "source": [
        "scores = model.evaluate(X_valid, y_valid, verbose=0)\n",
        "print(f\"{scores=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Med8GgsumOZX",
        "outputId": "a99bb866-0de3-462f-c0ae-1525ae0f9e15"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_valid)\n",
        "\n",
        "# print(f\"{np.argmax(y_pred, axis=1)=}\")\n",
        "# print(f\"{np.argmax(y_valid, axis=1)=}\")\n",
        "\n",
        "error_data_index = []\n",
        "for i, (yp, yt) in enumerate(zip(np.argmax(y_pred, axis=1), np.argmax(y_valid, axis=1))):\n",
        "    if yp != yt:\n",
        "        print(f\"index: {i}, truth: {GESTURES[yt]}, predicted: {GESTURES[yp]}\")\n",
        "        error_data_index.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "dYxrNLa_tbEI",
        "outputId": "157bff66-e04d-4fc6-8505-e0d3b550a627"
      },
      "outputs": [],
      "source": [
        "y_valid_not_onehot = np.argmax(y_valid, axis=1)\n",
        "y_pred_not_onehot = np.argmax(y_pred, axis=1)\n",
        "plt.figure(figsize=(10, 10))\n",
        "matrix_confusion = confusion_matrix(y_pred_not_onehot, y_valid_not_onehot)\n",
        "sns.heatmap(matrix_confusion, square=True, annot=False, cmap='Blues', fmt='d')\n",
        "\n",
        "for i in range(matrix_confusion.shape[0]):\n",
        "    for j in range(matrix_confusion.shape[1]):\n",
        "        plt.text(j+0.5, i+0.5, f'{matrix_confusion[i, j]}/{np.sum(matrix_confusion[i, :])}', \n",
        "                 horizontalalignment='center', verticalalignment='center', fontsize=12)\n",
        "\n",
        "plt.xlabel('predictions')\n",
        "plt.ylabel('ground truth')\n",
        "plt.xticks(np.arange(0.5, matrix_confusion.shape[0]+0.5), GESTURES_KEPT, rotation=45, fontsize=12)\n",
        "plt.yticks(np.arange(0.5, matrix_confusion.shape[0]+0.5), GESTURES_KEPT, rotation=45, fontsize=12)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "id": "HJrkHzcfDxRN",
        "outputId": "e4edfe68-cdc5-497f-fc94-788f60c797a0"
      },
      "outputs": [],
      "source": [
        "print(f\"total error data size: {len(error_data_index)}\")\n",
        "if(len(error_data_index)>0):\n",
        "    index = np.random.choice(error_data_index)\n",
        "\n",
        "    true_label = np.argmax(y_valid[index])\n",
        "    predicted_class = np.argmax(y_pred[index])\n",
        "\n",
        "    print(f\"{GESTURES[true_label]=}\")\n",
        "    print(f\"{GESTURES[predicted_class]=}\")\n",
        "\n",
        "    fig, axs = plt.subplots(3, 3, figsize=(15, 10))\n",
        "\n",
        "    raw_data = X_valid[index]\n",
        "    acc_axes = axs[:, :3].ravel()\n",
        "    acc_data = raw_data\n",
        "    acc_titles = [f'Imu{i}_acc_{xyz}' for i in range(3) for xyz in ['x', 'y', 'z']]\n",
        "\n",
        "    for ax, data, title in zip(acc_axes, acc_data.T, acc_titles):\n",
        "        ax.plot(data)\n",
        "        ax.set_title(title)\n",
        "        ax.set_ylim([-1.5 * 9.8, 1.5 * 9.8])\n",
        "\n",
        "    fig.suptitle(f'labeled: {GESTURES[true_label]}, predicted: {GESTURES[predicted_class]}')\n",
        "    plt.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cf_SnLotUIXu"
      },
      "source": [
        "# Explaination "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_4S-pRiULfn"
      },
      "outputs": [],
      "source": [
        "feature_importance = np.zeros(FEATURES_DIM+1)\n",
        "for feature in range(FEATURES_DIM):\n",
        "    X_valid_f = X_valid.copy()\n",
        "    X_valid_f[:, :, feature] = 0\n",
        "    feature_importance[feature] = model.evaluate(X_valid_f, y_valid, verbose=0)[0]\n",
        "feature_importance[-1] = model.evaluate(X_valid, y_valid, verbose=0)[0]\n",
        "\n",
        "feature_importance = feature_importance / feature_importance[-1]\n",
        "print(f\"{feature_importance=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jM_HRRVCUHVB"
      },
      "outputs": [],
      "source": [
        "titles = FEATURES_KEPT + ['Original']\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(titles, feature_importance)\n",
        "plt.xticks(rotation=90)\n",
        "plt.title('Feature Importance of different discarded features')\n",
        "plt.ylabel('Normalized Importance Ratio')\n",
        "plt.xlabel('Discarded Feature')\n",
        "for i in range(FEATURES_DIM+1):\n",
        "    plt.text(i, feature_importance[i], f'{feature_importance[i]:.2f}', horizontalalignment='center', verticalalignment='bottom', rotation=90, fontsize=12)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Timing Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "block_len = 10\n",
        "\n",
        "index = np.random.choice(len(df))\n",
        "data_id = df['data_id'].iloc[index]\n",
        "data = df['data'].iloc[index]\n",
        "label = df['label'].iloc[index]\n",
        "\n",
        "fig, axs = plt.subplots(3, 3, figsize=(15, 10), sharex=True, sharey=True,)\n",
        "acc_axes = axs[:, :3].ravel()\n",
        "acc_data = data.copy()\n",
        "acc_titles = [f'Imu{i}_acc_{xyz}' for i in range(3) for xyz in ['x', 'y', 'z']]\n",
        "\n",
        "crossentropy_losses = np.zeros(DATA_BUF_LEN)\n",
        "for i in range(0, DATA_BUF_LEN):\n",
        "    mask_data = data.copy()\n",
        "    start_index = max(0, i-block_len//2)\n",
        "    end_index = min(DATA_BUF_LEN, i+block_len//2)\n",
        "    mask_data[start_index:end_index, :] = mask_data[max(0, start_index-1),:]\n",
        "    pred = model.predict(mask_data.reshape(1, DATA_BUF_LEN, FEATURES_DIM), verbose=0)[0]\n",
        "    crossentropy_losses[i] = -np.sum(label * np.log(pred))\n",
        "\n",
        "# label the highest loss\n",
        "max_loss_index = np.argmax(crossentropy_losses)\n",
        "start_index = max(0, max_loss_index-block_len//2)\n",
        "end_index = min(DATA_BUF_LEN, max_loss_index+block_len//2)\n",
        "\n",
        "# plot the data\n",
        "lines = []\n",
        "for ax, a_data, title in zip(acc_axes, acc_data.T, acc_titles):\n",
        "    lines += ax.plot(a_data, label='acceleration')\n",
        "    ax.set_title(title)\n",
        "    ax.set_ylim([-1.5 * 9.8, 1.5 * 9.8])\n",
        "    ax.axvspan(start_index, end_index, alpha=0.5, color='red')\n",
        "\n",
        "    ax2 = ax.twinx()\n",
        "    lines += ax2.plot(crossentropy_losses, color='green', linewidth=0.7, linestyle='--', label='crossentropy loss')\n",
        "\n",
        "# get the unique colors in the plot\n",
        "colors_ = pd.unique([l.get_color() for l in lines])\n",
        "linewidths = pd.unique([l.get_linewidth() for l in lines])\n",
        "linestyles = pd.unique([l.get_linestyle() for l in lines])\n",
        "handles = [plt.Line2D([], [], color=c, linewidth=lw, linestyle=ls) for c, lw, ls in zip(colors_, linewidths, linestyles)]\n",
        "labels = [l.get_label() for l in lines]\n",
        "fig.legend(handles, labels)\n",
        "fig.suptitle(f'data_id: {data_id}\\nlabeled: {GESTURES[np.argmax(label)]}')\n",
        "plt.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExqD0F92bGNb"
      },
      "source": [
        "# Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t = datetime.datetime.now()\n",
        "t_str = f\"{t.year}_{t.month}_{t.day}-{t.hour}_{t.minute}\"\n",
        "acc_str = f\"{scores[1]:.2f}\" \n",
        "# model.save_weights(f'/home/ubuntu/FYP-ROS/weights/model_lstm_weights-{t_str}-acc{acc_str}.h5')\n",
        "# model.save(f'/home/ubuntu/FYP-ROS/weights/model_lstm-{t_str}-acc{acc_str}.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
